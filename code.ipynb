{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import pipeline\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the pdf and convert to pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader('File/HR.pdf')\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splits the pages into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 53 pages and split into 338 chunks\n"
     ]
    }
   ],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "docs = splitter.split_documents(pages)\n",
    "print(f\"âœ… Loaded {len(pages)} pages and split into {len(docs)} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding model\n",
    "    - Here m using an embedding hugging face model without the need of any token\n",
    "    - Embedding model converts the pdf text to dense numerical vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9y/v8tsc1ln7f73rw94jj42d8zw0000gn/T/ipykernel_3326/2479007218.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name='all-MiniLM-L6-v2')\n",
      "/Users/subhratarakesh/Documents/UPWORK/PortFolio/LLM/PDF_chatbot/rag_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(model_name='all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store the embedded vectors in chroma_db folder for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Stored embeddings in Chroma DB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9y/v8tsc1ln7f73rw94jj42d8zw0000gn/T/ipykernel_3326/1609182152.py:3: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  db.persist()\n"
     ]
    }
   ],
   "source": [
    "db = Chroma.from_documents(documents=docs, embedding=embedding_model, persist_directory='./chroma_db')\n",
    "db.persist()\n",
    "print(\"âœ… Stored embeddings in Chroma DB.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the LLM (text Generator)\n",
    "    Using a light weight transformer to genrate an answer\n",
    "    This wraps the HuggingFace pipeline as a LangChain-compatible LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "qa_pipeline = pipeline('text-generation', model='distilgpt2', max_new_tokens=100)\n",
    "llm = HuggingFacePipeline(pipeline=qa_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Chroma db into a retriever\n",
    "    - it wraps the chroma DB in a search interface\n",
    "    - when you ask a question, it uses cosine similarity to find the top relevant chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Retrieval QA chain\n",
    "    it connects the LLM with the retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm=llm, retriever = retriever) #it connects the llm with the retirver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now LangChain:** \n",
    "- Takes your question\n",
    "- Retrieves the most relevant text from Chroma\n",
    "- Passes it + the question to the LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask a question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– Answer: Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "http://nwthumanrights.ca/wp-content/uploads/2020/05/fn_handbook.pdf\n",
      "\n",
      "http://nwthumanrights.ca/wp-content/uploads/2020/05/fn_handbook.pdf\n",
      "\n",
      "https://www.csst.qc.ca/en/Pages/CSST_communications_french_only.aspx\n",
      "Charter of Human Rights and Freedoms\n",
      "\n",
      "https://www.csst.qc.ca/en/Pages/CSST_communications_french_only.aspx\n",
      "Charter of Human Rights and Freedoms\n",
      "\n",
      "Question: What is this document about?\n",
      "Helpful Answer:\n",
      "The document is a document about human rights related to human rights related to human rights related to human rights related to human rights related to human rights related to human rights related to human rights related to human rights related to human rights related to human rights related to human rights related to human rights related to human rights related to human rights related to human rights related to human rights related to human rights related to human rights related to human rights related to human rights related to human rights related to human rights related to human\n"
     ]
    }
   ],
   "source": [
    "query = 'What is this document about?'\n",
    "answer = qa.run(query)\n",
    "print(\"ðŸ¤– Answer:\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LangChain handles all:**\n",
    "- Retrieval\n",
    "- Combining chunks + question\n",
    "- Passing it to the model\n",
    "- Getting output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"File/HR.pdf\")  \n",
    "pages = loader.load()   ## conver the pdf into pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 53 pages and split into 338 chunks.\n"
     ]
    }
   ],
   "source": [
    "## converting it to chunk of text with 500 words\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "docs = splitter.split_documents(pages)\n",
    "print(f\"âœ… Loaded {len(pages)} pages and split into {len(docs)} chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import sentence_transformers python package. Please install it with `pip install sentence-transformers`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/UPWORK/PortFolio/LLM/PDF_chatbot/rag_env/lib/python3.10/site-packages/langchain_community/embeddings/huggingface.py:84\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/Documents/UPWORK/PortFolio/LLM/PDF_chatbot/rag_env/lib/python3.10/site-packages/sentence_transformers/__init__.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCrossEncoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n",
      "File \u001b[0;32m~/Documents/UPWORK/PortFolio/LLM/PDF_chatbot/rag_env/lib/python3.10/site-packages/sentence_transformers/cross_encoder/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCrossEncoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[1;32m      3\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCrossEncoder\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/UPWORK/PortFolio/LLM/PDF_chatbot/rag_env/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:12\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautonotebook\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm, trange\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoConfig, AutoModelForSequenceClassification, AutoTokenizer, is_torch_npu_available\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenization_utils_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BatchEncoding\n",
      "File \u001b[0;32m~/Documents/UPWORK/PortFolio/LLM/PDF_chatbot/rag_env/lib/python3.10/site-packages/transformers/utils/import_utils.py:2154\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[0;32m~/Documents/UPWORK/PortFolio/LLM/PDF_chatbot/rag_env/lib/python3.10/site-packages/transformers/utils/import_utils.py:2184\u001b[0m, in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[0;32m~/Documents/UPWORK/PortFolio/LLM/PDF_chatbot/rag_env/lib/python3.10/site-packages/transformers/utils/import_utils.py:2182\u001b[0m, in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.10/3.10.18/Frameworks/Python.framework/Versions/3.10/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/UPWORK/PortFolio/LLM/PDF_chatbot/rag_env/lib/python3.10/site-packages/transformers/models/__init__.py:15\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m     albert,\n\u001b[1;32m     17\u001b[0m     align,\n\u001b[1;32m     18\u001b[0m     altclip,\n\u001b[1;32m     19\u001b[0m     audio_spectrogram_transformer,\n\u001b[1;32m     20\u001b[0m     auto,\n\u001b[1;32m     21\u001b[0m     autoformer,\n\u001b[1;32m     22\u001b[0m     bark,\n\u001b[1;32m     23\u001b[0m     bart,\n\u001b[1;32m     24\u001b[0m     barthez,\n\u001b[1;32m     25\u001b[0m     bartpho,\n\u001b[1;32m     26\u001b[0m     beit,\n\u001b[1;32m     27\u001b[0m     bert,\n\u001b[1;32m     28\u001b[0m     bert_generation,\n\u001b[1;32m     29\u001b[0m     bert_japanese,\n\u001b[1;32m     30\u001b[0m     bertweet,\n\u001b[1;32m     31\u001b[0m     big_bird,\n\u001b[1;32m     32\u001b[0m     bigbird_pegasus,\n\u001b[1;32m     33\u001b[0m     biogpt,\n\u001b[1;32m     34\u001b[0m     bit,\n\u001b[1;32m     35\u001b[0m     blenderbot,\n\u001b[1;32m     36\u001b[0m     blenderbot_small,\n\u001b[1;32m     37\u001b[0m     blip,\n\u001b[1;32m     38\u001b[0m     blip_2,\n\u001b[1;32m     39\u001b[0m     bloom,\n\u001b[1;32m     40\u001b[0m     bridgetower,\n\u001b[1;32m     41\u001b[0m     bros,\n\u001b[1;32m     42\u001b[0m     byt5,\n\u001b[1;32m     43\u001b[0m     camembert,\n\u001b[1;32m     44\u001b[0m     canine,\n\u001b[1;32m     45\u001b[0m     chinese_clip,\n\u001b[1;32m     46\u001b[0m     clap,\n\u001b[1;32m     47\u001b[0m     clip,\n\u001b[1;32m     48\u001b[0m     clipseg,\n\u001b[1;32m     49\u001b[0m     code_llama,\n\u001b[1;32m     50\u001b[0m     codegen,\n\u001b[1;32m     51\u001b[0m     conditional_detr,\n\u001b[1;32m     52\u001b[0m     convbert,\n\u001b[1;32m     53\u001b[0m     convnext,\n\u001b[1;32m     54\u001b[0m     convnextv2,\n\u001b[1;32m     55\u001b[0m     cpm,\n\u001b[1;32m     56\u001b[0m     cpmant,\n\u001b[1;32m     57\u001b[0m     ctrl,\n\u001b[1;32m     58\u001b[0m     cvt,\n\u001b[1;32m     59\u001b[0m     data2vec,\n\u001b[1;32m     60\u001b[0m     deberta,\n\u001b[1;32m     61\u001b[0m     deberta_v2,\n\u001b[1;32m     62\u001b[0m     decision_transformer,\n\u001b[1;32m     63\u001b[0m     deformable_detr,\n\u001b[1;32m     64\u001b[0m     deit,\n\u001b[1;32m     65\u001b[0m     deprecated,\n\u001b[1;32m     66\u001b[0m     deta,\n\u001b[1;32m     67\u001b[0m     detr,\n\u001b[1;32m     68\u001b[0m     dialogpt,\n\u001b[1;32m     69\u001b[0m     dinat,\n\u001b[1;32m     70\u001b[0m     dinov2,\n\u001b[1;32m     71\u001b[0m     distilbert,\n\u001b[1;32m     72\u001b[0m     dit,\n\u001b[1;32m     73\u001b[0m     donut,\n\u001b[1;32m     74\u001b[0m     dpr,\n\u001b[1;32m     75\u001b[0m     dpt,\n\u001b[1;32m     76\u001b[0m     efficientformer,\n\u001b[1;32m     77\u001b[0m     efficientnet,\n\u001b[1;32m     78\u001b[0m     electra,\n\u001b[1;32m     79\u001b[0m     encodec,\n\u001b[1;32m     80\u001b[0m     encoder_decoder,\n\u001b[1;32m     81\u001b[0m     ernie,\n\u001b[1;32m     82\u001b[0m     ernie_m,\n\u001b[1;32m     83\u001b[0m     esm,\n\u001b[1;32m     84\u001b[0m     falcon,\n\u001b[1;32m     85\u001b[0m     flaubert,\n\u001b[1;32m     86\u001b[0m     flava,\n\u001b[1;32m     87\u001b[0m     fnet,\n\u001b[1;32m     88\u001b[0m     focalnet,\n\u001b[1;32m     89\u001b[0m     fsmt,\n\u001b[1;32m     90\u001b[0m     funnel,\n\u001b[1;32m     91\u001b[0m     fuyu,\n\u001b[1;32m     92\u001b[0m     git,\n\u001b[1;32m     93\u001b[0m     glpn,\n\u001b[1;32m     94\u001b[0m     gpt2,\n\u001b[1;32m     95\u001b[0m     gpt_bigcode,\n\u001b[1;32m     96\u001b[0m     gpt_neo,\n\u001b[1;32m     97\u001b[0m     gpt_neox,\n\u001b[1;32m     98\u001b[0m     gpt_neox_japanese,\n\u001b[1;32m     99\u001b[0m     gpt_sw3,\n\u001b[1;32m    100\u001b[0m     gptj,\n\u001b[1;32m    101\u001b[0m     gptsan_japanese,\n\u001b[1;32m    102\u001b[0m     graphormer,\n\u001b[1;32m    103\u001b[0m     groupvit,\n\u001b[1;32m    104\u001b[0m     herbert,\n\u001b[1;32m    105\u001b[0m     hubert,\n\u001b[1;32m    106\u001b[0m     ibert,\n\u001b[1;32m    107\u001b[0m     idefics,\n\u001b[1;32m    108\u001b[0m     imagegpt,\n\u001b[1;32m    109\u001b[0m     informer,\n\u001b[1;32m    110\u001b[0m     instructblip,\n\u001b[1;32m    111\u001b[0m     jukebox,\n\u001b[1;32m    112\u001b[0m     kosmos2,\n\u001b[1;32m    113\u001b[0m     layoutlm,\n\u001b[1;32m    114\u001b[0m     layoutlmv2,\n\u001b[1;32m    115\u001b[0m     layoutlmv3,\n\u001b[1;32m    116\u001b[0m     layoutxlm,\n\u001b[1;32m    117\u001b[0m     led,\n\u001b[1;32m    118\u001b[0m     levit,\n\u001b[1;32m    119\u001b[0m     lilt,\n\u001b[1;32m    120\u001b[0m     llama,\n\u001b[1;32m    121\u001b[0m     longformer,\n\u001b[1;32m    122\u001b[0m     longt5,\n\u001b[1;32m    123\u001b[0m     luke,\n\u001b[1;32m    124\u001b[0m     lxmert,\n\u001b[1;32m    125\u001b[0m     m2m_100,\n\u001b[1;32m    126\u001b[0m     marian,\n\u001b[1;32m    127\u001b[0m     markuplm,\n\u001b[1;32m    128\u001b[0m     mask2former,\n\u001b[1;32m    129\u001b[0m     maskformer,\n\u001b[1;32m    130\u001b[0m     mbart,\n\u001b[1;32m    131\u001b[0m     mbart50,\n\u001b[1;32m    132\u001b[0m     mega,\n\u001b[1;32m    133\u001b[0m     megatron_bert,\n\u001b[1;32m    134\u001b[0m     megatron_gpt2,\n\u001b[1;32m    135\u001b[0m     mgp_str,\n\u001b[1;32m    136\u001b[0m     mistral,\n\u001b[1;32m    137\u001b[0m     mluke,\n\u001b[1;32m    138\u001b[0m     mobilebert,\n\u001b[1;32m    139\u001b[0m     mobilenet_v1,\n\u001b[1;32m    140\u001b[0m     mobilenet_v2,\n\u001b[1;32m    141\u001b[0m     mobilevit,\n\u001b[1;32m    142\u001b[0m     mobilevitv2,\n\u001b[1;32m    143\u001b[0m     mpnet,\n\u001b[1;32m    144\u001b[0m     mpt,\n\u001b[1;32m    145\u001b[0m     mra,\n\u001b[1;32m    146\u001b[0m     mt5,\n\u001b[1;32m    147\u001b[0m     musicgen,\n\u001b[1;32m    148\u001b[0m     mvp,\n\u001b[1;32m    149\u001b[0m     nat,\n\u001b[1;32m    150\u001b[0m     nezha,\n\u001b[1;32m    151\u001b[0m     nllb,\n\u001b[1;32m    152\u001b[0m     nllb_moe,\n\u001b[1;32m    153\u001b[0m     nougat,\n\u001b[1;32m    154\u001b[0m     nystromformer,\n\u001b[1;32m    155\u001b[0m     oneformer,\n\u001b[1;32m    156\u001b[0m     openai,\n\u001b[1;32m    157\u001b[0m     opt,\n\u001b[1;32m    158\u001b[0m     owlv2,\n\u001b[1;32m    159\u001b[0m     owlvit,\n\u001b[1;32m    160\u001b[0m     pegasus,\n\u001b[1;32m    161\u001b[0m     pegasus_x,\n\u001b[1;32m    162\u001b[0m     perceiver,\n\u001b[1;32m    163\u001b[0m     persimmon,\n\u001b[1;32m    164\u001b[0m     phobert,\n\u001b[1;32m    165\u001b[0m     pix2struct,\n\u001b[1;32m    166\u001b[0m     plbart,\n\u001b[1;32m    167\u001b[0m     poolformer,\n\u001b[1;32m    168\u001b[0m     pop2piano,\n\u001b[1;32m    169\u001b[0m     prophetnet,\n\u001b[1;32m    170\u001b[0m     pvt,\n\u001b[1;32m    171\u001b[0m     qdqbert,\n\u001b[1;32m    172\u001b[0m     rag,\n\u001b[1;32m    173\u001b[0m     realm,\n\u001b[1;32m    174\u001b[0m     reformer,\n\u001b[1;32m    175\u001b[0m     regnet,\n\u001b[1;32m    176\u001b[0m     rembert,\n\u001b[1;32m    177\u001b[0m     resnet,\n\u001b[1;32m    178\u001b[0m     roberta,\n\u001b[1;32m    179\u001b[0m     roberta_prelayernorm,\n\u001b[1;32m    180\u001b[0m     roc_bert,\n\u001b[1;32m    181\u001b[0m     roformer,\n\u001b[1;32m    182\u001b[0m     rwkv,\n\u001b[1;32m    183\u001b[0m     sam,\n\u001b[1;32m    184\u001b[0m     seamless_m4t,\n\u001b[1;32m    185\u001b[0m     segformer,\n\u001b[1;32m    186\u001b[0m     sew,\n\u001b[1;32m    187\u001b[0m     sew_d,\n\u001b[1;32m    188\u001b[0m     speech_encoder_decoder,\n\u001b[1;32m    189\u001b[0m     speech_to_text,\n\u001b[1;32m    190\u001b[0m     speech_to_text_2,\n\u001b[1;32m    191\u001b[0m     speecht5,\n\u001b[1;32m    192\u001b[0m     splinter,\n\u001b[1;32m    193\u001b[0m     squeezebert,\n\u001b[1;32m    194\u001b[0m     swiftformer,\n\u001b[1;32m    195\u001b[0m     swin,\n\u001b[1;32m    196\u001b[0m     swin2sr,\n\u001b[1;32m    197\u001b[0m     swinv2,\n\u001b[1;32m    198\u001b[0m     switch_transformers,\n\u001b[1;32m    199\u001b[0m     t5,\n\u001b[1;32m    200\u001b[0m     table_transformer,\n\u001b[1;32m    201\u001b[0m     tapas,\n\u001b[1;32m    202\u001b[0m     time_series_transformer,\n\u001b[1;32m    203\u001b[0m     timesformer,\n\u001b[1;32m    204\u001b[0m     timm_backbone,\n\u001b[1;32m    205\u001b[0m     transfo_xl,\n\u001b[1;32m    206\u001b[0m     trocr,\n\u001b[1;32m    207\u001b[0m     tvlt,\n\u001b[1;32m    208\u001b[0m     umt5,\n\u001b[1;32m    209\u001b[0m     unispeech,\n\u001b[1;32m    210\u001b[0m     unispeech_sat,\n\u001b[1;32m    211\u001b[0m     upernet,\n\u001b[1;32m    212\u001b[0m     videomae,\n\u001b[1;32m    213\u001b[0m     vilt,\n\u001b[1;32m    214\u001b[0m     vision_encoder_decoder,\n\u001b[1;32m    215\u001b[0m     vision_text_dual_encoder,\n\u001b[1;32m    216\u001b[0m     visual_bert,\n\u001b[1;32m    217\u001b[0m     vit,\n\u001b[1;32m    218\u001b[0m     vit_hybrid,\n\u001b[1;32m    219\u001b[0m     vit_mae,\n\u001b[1;32m    220\u001b[0m     vit_msn,\n\u001b[1;32m    221\u001b[0m     vitdet,\n\u001b[1;32m    222\u001b[0m     vitmatte,\n\u001b[1;32m    223\u001b[0m     vits,\n\u001b[1;32m    224\u001b[0m     vivit,\n\u001b[1;32m    225\u001b[0m     wav2vec2,\n\u001b[1;32m    226\u001b[0m     wav2vec2_conformer,\n\u001b[1;32m    227\u001b[0m     wav2vec2_phoneme,\n\u001b[1;32m    228\u001b[0m     wav2vec2_with_lm,\n\u001b[1;32m    229\u001b[0m     wavlm,\n\u001b[1;32m    230\u001b[0m     whisper,\n\u001b[1;32m    231\u001b[0m     x_clip,\n\u001b[1;32m    232\u001b[0m     xglm,\n\u001b[1;32m    233\u001b[0m     xlm,\n\u001b[1;32m    234\u001b[0m     xlm_prophetnet,\n\u001b[1;32m    235\u001b[0m     xlm_roberta,\n\u001b[1;32m    236\u001b[0m     xlm_roberta_xl,\n\u001b[1;32m    237\u001b[0m     xlnet,\n\u001b[1;32m    238\u001b[0m     xmod,\n\u001b[1;32m    239\u001b[0m     yolos,\n\u001b[1;32m    240\u001b[0m     yoso,\n\u001b[1;32m    241\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/UPWORK/PortFolio/LLM/PDF_chatbot/rag_env/lib/python3.10/site-packages/transformers/models/dpt/__init__.py:16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _LazyModule, is_tokenizers_available, is_torch_available, is_vision_available\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OptionalDependencyNotAvailable\n",
      "File \u001b[0;32m~/Documents/UPWORK/PortFolio/LLM/PDF_chatbot/rag_env/lib/python3.10/site-packages/transformers/file_utils.py:25\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Backward compatibility imports, to make sure all those objects can be found in file_utils\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     26\u001b[0m     CLOUDFRONT_DISTRIB_PREFIX,\n\u001b[1;32m     27\u001b[0m     CONFIG_NAME,\n\u001b[1;32m     28\u001b[0m     DISABLE_TELEMETRY,\n\u001b[1;32m     29\u001b[0m     DUMMY_INPUTS,\n\u001b[1;32m     30\u001b[0m     DUMMY_MASK,\n\u001b[1;32m     31\u001b[0m     ENV_VARS_TRUE_AND_AUTO_VALUES,\n\u001b[1;32m     32\u001b[0m     ENV_VARS_TRUE_VALUES,\n\u001b[1;32m     33\u001b[0m     FEATURE_EXTRACTOR_NAME,\n\u001b[1;32m     34\u001b[0m     FLAX_WEIGHTS_NAME,\n\u001b[1;32m     35\u001b[0m     HF_MODULES_CACHE,\n\u001b[1;32m     36\u001b[0m     HUGGINGFACE_CO_PREFIX,\n\u001b[1;32m     37\u001b[0m     HUGGINGFACE_CO_RESOLVE_ENDPOINT,\n\u001b[1;32m     38\u001b[0m     MODEL_CARD_NAME,\n\u001b[1;32m     39\u001b[0m     MULTIPLE_CHOICE_DUMMY_INPUTS,\n\u001b[1;32m     40\u001b[0m     PYTORCH_PRETRAINED_BERT_CACHE,\n\u001b[1;32m     41\u001b[0m     PYTORCH_TRANSFORMERS_CACHE,\n\u001b[1;32m     42\u001b[0m     S3_BUCKET_PREFIX,\n\u001b[1;32m     43\u001b[0m     SENTENCEPIECE_UNDERLINE,\n\u001b[1;32m     44\u001b[0m     SPIECE_UNDERLINE,\n\u001b[1;32m     45\u001b[0m     TF2_WEIGHTS_NAME,\n\u001b[1;32m     46\u001b[0m     TF_WEIGHTS_NAME,\n\u001b[1;32m     47\u001b[0m     TORCH_FX_REQUIRED_VERSION,\n\u001b[1;32m     48\u001b[0m     TRANSFORMERS_CACHE,\n\u001b[1;32m     49\u001b[0m     TRANSFORMERS_DYNAMIC_MODULE_NAME,\n\u001b[1;32m     50\u001b[0m     USE_JAX,\n\u001b[1;32m     51\u001b[0m     USE_TF,\n\u001b[1;32m     52\u001b[0m     USE_TORCH,\n\u001b[1;32m     53\u001b[0m     WEIGHTS_INDEX_NAME,\n\u001b[1;32m     54\u001b[0m     WEIGHTS_NAME,\n\u001b[1;32m     55\u001b[0m     ContextManagers,\n\u001b[1;32m     56\u001b[0m     DummyObject,\n\u001b[1;32m     57\u001b[0m     EntryNotFoundError,\n\u001b[1;32m     58\u001b[0m     ExplicitEnum,\n\u001b[1;32m     59\u001b[0m     ModelOutput,\n\u001b[1;32m     60\u001b[0m     PaddingStrategy,\n\u001b[1;32m     61\u001b[0m     PushToHubMixin,\n\u001b[1;32m     62\u001b[0m     RepositoryNotFoundError,\n\u001b[1;32m     63\u001b[0m     RevisionNotFoundError,\n\u001b[1;32m     64\u001b[0m     TensorType,\n\u001b[1;32m     65\u001b[0m     _LazyModule,\n\u001b[1;32m     66\u001b[0m     add_code_sample_docstrings,\n\u001b[1;32m     67\u001b[0m     add_end_docstrings,\n\u001b[1;32m     68\u001b[0m     add_start_docstrings,\n\u001b[1;32m     69\u001b[0m     add_start_docstrings_to_model_forward,\n\u001b[1;32m     70\u001b[0m     cached_property,\n\u001b[1;32m     71\u001b[0m     copy_func,\n\u001b[1;32m     72\u001b[0m     default_cache_path,\n\u001b[1;32m     73\u001b[0m     define_sagemaker_information,\n\u001b[1;32m     74\u001b[0m     get_cached_models,\n\u001b[1;32m     75\u001b[0m     get_file_from_repo,\n\u001b[1;32m     76\u001b[0m     get_torch_version,\n\u001b[1;32m     77\u001b[0m     has_file,\n\u001b[1;32m     78\u001b[0m     http_user_agent,\n\u001b[1;32m     79\u001b[0m     is_apex_available,\n\u001b[1;32m     80\u001b[0m     is_bs4_available,\n\u001b[1;32m     81\u001b[0m     is_coloredlogs_available,\n\u001b[1;32m     82\u001b[0m     is_datasets_available,\n\u001b[1;32m     83\u001b[0m     is_detectron2_available,\n\u001b[1;32m     84\u001b[0m     is_faiss_available,\n\u001b[1;32m     85\u001b[0m     is_flax_available,\n\u001b[1;32m     86\u001b[0m     is_ftfy_available,\n\u001b[1;32m     87\u001b[0m     is_in_notebook,\n\u001b[1;32m     88\u001b[0m     is_ipex_available,\n\u001b[1;32m     89\u001b[0m     is_librosa_available,\n\u001b[1;32m     90\u001b[0m     is_offline_mode,\n\u001b[1;32m     91\u001b[0m     is_onnx_available,\n\u001b[1;32m     92\u001b[0m     is_pandas_available,\n\u001b[1;32m     93\u001b[0m     is_phonemizer_available,\n\u001b[1;32m     94\u001b[0m     is_protobuf_available,\n\u001b[1;32m     95\u001b[0m     is_psutil_available,\n\u001b[1;32m     96\u001b[0m     is_py3nvml_available,\n\u001b[1;32m     97\u001b[0m     is_pyctcdecode_available,\n\u001b[1;32m     98\u001b[0m     is_pytesseract_available,\n\u001b[1;32m     99\u001b[0m     is_pytorch_quantization_available,\n\u001b[1;32m    100\u001b[0m     is_rjieba_available,\n\u001b[1;32m    101\u001b[0m     is_sagemaker_dp_enabled,\n\u001b[1;32m    102\u001b[0m     is_sagemaker_mp_enabled,\n\u001b[1;32m    103\u001b[0m     is_scipy_available,\n\u001b[1;32m    104\u001b[0m     is_sentencepiece_available,\n\u001b[1;32m    105\u001b[0m     is_seqio_available,\n\u001b[1;32m    106\u001b[0m     is_sklearn_available,\n\u001b[1;32m    107\u001b[0m     is_soundfile_availble,\n\u001b[1;32m    108\u001b[0m     is_spacy_available,\n\u001b[1;32m    109\u001b[0m     is_speech_available,\n\u001b[1;32m    110\u001b[0m     is_tensor,\n\u001b[1;32m    111\u001b[0m     is_tensorflow_probability_available,\n\u001b[1;32m    112\u001b[0m     is_tf2onnx_available,\n\u001b[1;32m    113\u001b[0m     is_tf_available,\n\u001b[1;32m    114\u001b[0m     is_timm_available,\n\u001b[1;32m    115\u001b[0m     is_tokenizers_available,\n\u001b[1;32m    116\u001b[0m     is_torch_available,\n\u001b[1;32m    117\u001b[0m     is_torch_bf16_available,\n\u001b[1;32m    118\u001b[0m     is_torch_cuda_available,\n\u001b[1;32m    119\u001b[0m     is_torch_fx_available,\n\u001b[1;32m    120\u001b[0m     is_torch_fx_proxy,\n\u001b[1;32m    121\u001b[0m     is_torch_mps_available,\n\u001b[1;32m    122\u001b[0m     is_torch_tf32_available,\n\u001b[1;32m    123\u001b[0m     is_torch_tpu_available,\n\u001b[1;32m    124\u001b[0m     is_torchaudio_available,\n\u001b[1;32m    125\u001b[0m     is_training_run_on_sagemaker,\n\u001b[1;32m    126\u001b[0m     is_vision_available,\n\u001b[1;32m    127\u001b[0m     replace_return_docstrings,\n\u001b[1;32m    128\u001b[0m     requires_backends,\n\u001b[1;32m    129\u001b[0m     to_numpy,\n\u001b[1;32m    130\u001b[0m     to_py_obj,\n\u001b[1;32m    131\u001b[0m     torch_only_method,\n\u001b[1;32m    132\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'get_cached_models' from 'transformers.utils' (/Users/subhratarakesh/Documents/UPWORK/PortFolio/LLM/PDF_chatbot/rag_env/lib/python3.10/site-packages/transformers/utils/__init__.py)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# token free embedding\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m embedding_model \u001b[38;5;241m=\u001b[39m \u001b[43mHuggingFaceEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msentence-transformers/all-MiniLM-L6-v2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/UPWORK/PortFolio/LLM/PDF_chatbot/rag_env/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:222\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     emit_warning()\n\u001b[0;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/UPWORK/PortFolio/LLM/PDF_chatbot/rag_env/lib/python3.10/site-packages/langchain_community/embeddings/huggingface.py:87\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import sentence_transformers python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install sentence-transformers`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     90\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m sentence_transformers\u001b[38;5;241m.\u001b[39mSentenceTransformer(\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name, cache_folder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_folder, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_kwargs\n\u001b[1;32m     94\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: Could not import sentence_transformers python package. Please install it with `pip install sentence-transformers`."
     ]
    }
   ],
   "source": [
    "# token free embedding\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in ./rag_env/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in ./rag_env/lib/python3.10/site-packages (from sentence-transformers) (4.53.1)\n",
      "Requirement already satisfied: tqdm in ./rag_env/lib/python3.10/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in ./rag_env/lib/python3.10/site-packages (from sentence-transformers) (2.2.2)\n",
      "Requirement already satisfied: torchvision in ./rag_env/lib/python3.10/site-packages (from sentence-transformers) (0.17.2)\n",
      "Requirement already satisfied: numpy in ./rag_env/lib/python3.10/site-packages (from sentence-transformers) (2.2.6)\n",
      "Requirement already satisfied: scikit-learn in ./rag_env/lib/python3.10/site-packages (from sentence-transformers) (1.7.0)\n",
      "Requirement already satisfied: scipy in ./rag_env/lib/python3.10/site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: nltk in ./rag_env/lib/python3.10/site-packages (from sentence-transformers) (3.9.1)\n",
      "Requirement already satisfied: sentencepiece in ./rag_env/lib/python3.10/site-packages (from sentence-transformers) (0.2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in ./rag_env/lib/python3.10/site-packages (from sentence-transformers) (0.33.2)\n",
      "Requirement already satisfied: filelock in ./rag_env/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./rag_env/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./rag_env/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./rag_env/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in ./rag_env/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./rag_env/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./rag_env/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./rag_env/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2025.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./rag_env/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./rag_env/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (1.1.5)\n",
      "Requirement already satisfied: sympy in ./rag_env/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./rag_env/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./rag_env/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./rag_env/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: click in ./rag_env/lib/python3.10/site-packages (from nltk->sentence-transformers) (8.2.1)\n",
      "Requirement already satisfied: joblib in ./rag_env/lib/python3.10/site-packages (from nltk->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./rag_env/lib/python3.10/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./rag_env/lib/python3.10/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./rag_env/lib/python3.10/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./rag_env/lib/python3.10/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2025.6.15)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./rag_env/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./rag_env/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./rag_env/lib/python3.10/site-packages (from torchvision->sentence-transformers) (11.3.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_community\n",
      "  Using cached langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.66 (from langchain_community)\n",
      "  Using cached langchain_core-0.3.68-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain<1.0.0,>=0.3.26 (from langchain_community)\n",
      "  Using cached langchain-0.3.26-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain_community)\n",
      "  Using cached sqlalchemy-2.0.41-cp310-cp310-macosx_10_9_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in ./rag_env/lib/python3.10/site-packages (from langchain_community) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./rag_env/lib/python3.10/site-packages (from langchain_community) (6.0.2)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain_community)\n",
      "  Using cached aiohttp-3.12.13-cp310-cp310-macosx_10_9_x86_64.whl.metadata (7.6 kB)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain_community)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Using cached pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting langsmith>=0.1.125 (from langchain_community)\n",
      "  Using cached langsmith-0.4.4-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
      "  Using cached httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting numpy>=1.26.2 (from langchain_community)\n",
      "  Using cached numpy-2.2.6-cp310-cp310-macosx_14_0_x86_64.whl.metadata (62 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Using cached frozenlist-1.7.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Using cached multidict-6.6.3-cp310-cp310-macosx_10_9_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Using cached propcache-0.3.2-cp310-cp310-macosx_10_9_x86_64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Using cached yarl-1.20.1-cp310-cp310-macosx_10_9_x86_64.whl.metadata (73 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain<1.0.0,>=0.3.26->langchain_community)\n",
      "  Using cached langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain<1.0.0,>=0.3.26->langchain_community)\n",
      "  Using cached pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.66->langchain_community)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core<1.0.0,>=0.3.66->langchain_community)\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./rag_env/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (4.14.1)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain_community)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community)\n",
      "  Using cached pydantic_core-2.33.2-cp310-cp310-macosx_10_12_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
      "  Using cached python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./rag_env/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./rag_env/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./rag_env/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./rag_env/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2025.6.15)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain_community)\n",
      "  Using cached greenlet-3.2.3-cp310-cp310-macosx_11_0_universal2.whl.metadata (4.1 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Using cached mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith>=0.1.125->langchain_community)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith>=0.1.125->langchain_community)\n",
      "  Using cached orjson-3.10.18-cp310-cp310-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (41 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith>=0.1.125->langchain_community)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith>=0.1.125->langchain_community)\n",
      "  Using cached zstandard-0.23.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community)\n",
      "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./rag_env/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.3.0)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Using cached langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
      "Using cached aiohttp-3.12.13-cp310-cp310-macosx_10_9_x86_64.whl (478 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Using cached langchain-0.3.26-py3-none-any.whl (1.0 MB)\n",
      "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Using cached langchain_core-0.3.68-py3-none-any.whl (441 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached multidict-6.6.3-cp310-cp310-macosx_10_9_x86_64.whl (44 kB)\n",
      "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Using cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Using cached pydantic_core-2.33.2-cp310-cp310-macosx_10_12_x86_64.whl (2.0 MB)\n",
      "Using cached pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "Using cached sqlalchemy-2.0.41-cp310-cp310-macosx_10_9_x86_64.whl (2.1 MB)\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached yarl-1.20.1-cp310-cp310-macosx_10_9_x86_64.whl (90 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached frozenlist-1.7.0-cp310-cp310-macosx_10_9_x86_64.whl (47 kB)\n",
      "Using cached greenlet-3.2.3-cp310-cp310-macosx_11_0_universal2.whl (268 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached langsmith-0.4.4-py3-none-any.whl (367 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached orjson-3.10.18-cp310-cp310-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (248 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached zstandard-0.23.0-cp310-cp310-macosx_10_9_x86_64.whl (788 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Using cached numpy-2.2.6-cp310-cp310-macosx_14_0_x86_64.whl (6.9 MB)\n",
      "Using cached propcache-0.3.2-cp310-cp310-macosx_10_9_x86_64.whl (43 kB)\n",
      "Using cached python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Using cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: zstandard, typing-inspection, tenacity, sniffio, python-dotenv, pydantic-core, propcache, packaging, orjson, numpy, mypy-extensions, multidict, jsonpointer, httpx-sse, h11, greenlet, frozenlist, attrs, async-timeout, annotated-types, aiohappyeyeballs, yarl, typing-inspect, SQLAlchemy, requests-toolbelt, pydantic, marshmallow, jsonpatch, httpcore, anyio, aiosignal, pydantic-settings, httpx, dataclasses-json, aiohttp, langsmith, langchain-core, langchain-text-splitters, langchain, langchain_community\n",
      "\u001b[2K  Attempting uninstall: packagingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/40\u001b[0m [python-dotenv]\n",
      "\u001b[2K    Found existing installation: packaging 25.0â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/40\u001b[0m [python-dotenv]\n",
      "\u001b[2K    Uninstalling packaging-25.0:â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/40\u001b[0m [python-dotenv]\n",
      "\u001b[2K      Successfully uninstalled packaging-25.0â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/40\u001b[0m [python-dotenv]\n",
      "\u001b[2K  Attempting uninstall: numpy\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 7/40\u001b[0m [packaging]\n",
      "\u001b[2K    Found existing installation: numpy 1.24.4â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 7/40\u001b[0m [packaging]\n",
      "\u001b[2K    Uninstalling numpy-1.24.4:â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 7/40\u001b[0m [packaging]\n",
      "\u001b[2K      Successfully uninstalled numpy-1.24.4â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 7/40\u001b[0m [packaging]\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40/40\u001b[0m [langchain_community]ommunity]ore]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed SQLAlchemy-2.0.41 aiohappyeyeballs-2.6.1 aiohttp-3.12.13 aiosignal-1.4.0 annotated-types-0.7.0 anyio-4.9.0 async-timeout-4.0.3 attrs-25.3.0 dataclasses-json-0.6.7 frozenlist-1.7.0 greenlet-3.2.3 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 httpx-sse-0.4.1 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.26 langchain-core-0.3.68 langchain-text-splitters-0.3.8 langchain_community-0.3.27 langsmith-0.4.4 marshmallow-3.26.1 multidict-6.6.3 mypy-extensions-1.1.0 numpy-2.2.6 orjson-3.10.18 packaging-24.2 propcache-0.3.2 pydantic-2.11.7 pydantic-core-2.33.2 pydantic-settings-2.10.1 python-dotenv-1.1.1 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.1.2 typing-inspect-0.9.0 typing-inspection-0.4.1 yarl-1.20.1 zstandard-0.23.0\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: sentence-transformers\n",
      "Version: 2.2.2\n",
      "Summary: Multilingual text embeddings\n",
      "Home-page: https://github.com/UKPLab/sentence-transformers\n",
      "Author: Nils Reimers\n",
      "Author-email: info@nils-reimers.de\n",
      "License: Apache License 2.0\n",
      "Location: /Users/subhratarakesh/Documents/UPWORK/PortFolio/LLM/PDF_chatbot/rag_env/lib/python3.10/site-packages\n",
      "Requires: huggingface-hub, nltk, numpy, scikit-learn, scipy, sentencepiece, torch, torchvision, tqdm, transformers\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "! pip show sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Using cached pypdf-5.7.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in ./rag_env/lib/python3.10/site-packages (from pypdf) (4.14.1)\n",
      "Using cached pypdf-5.7.0-py3-none-any.whl (305 kB)\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-5.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/subhratarakesh/Documents/UPWORK/PortFolio/LLM/PDF_chatbot/rag_env/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence-transformers    2.2.2\n",
      "sentencepiece            0.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list | grep sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "! source rag_env/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'cached_download' from 'huggingface_hub' (/Users/subhratarakesh/Documents/UPWORK/PortFolio/LLM/PDF_chatbot/rag_env/lib/python3.10/site-packages/huggingface_hub/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n",
      "File \u001b[0;32m~/Documents/UPWORK/PortFolio/LLM/PDF_chatbot/rag_env/lib/python3.10/site-packages/sentence_transformers/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.2.2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m __MODEL_HUB_ORGANIZATION__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence-transformers\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentencesDataset, ParallelSentencesDataset\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mLoggingHandler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LoggingHandler\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceTransformer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n",
      "File \u001b[0;32m~/Documents/UPWORK/PortFolio/LLM/PDF_chatbot/rag_env/lib/python3.10/site-packages/sentence_transformers/datasets/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mDenoisingAutoEncoderDataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DenoisingAutoEncoderDataset\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mNoDuplicatesDataLoader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NoDuplicatesDataLoader\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mParallelSentencesDataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentencesDataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentencesDataset\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceLabelDataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceLabelDataset\n",
      "File \u001b[0;32m~/Documents/UPWORK/PortFolio/LLM/PDF_chatbot/rag_env/lib/python3.10/site-packages/sentence_transformers/datasets/ParallelSentencesDataset.py:4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgzip\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InputExample\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List\n",
      "File \u001b[0;32m~/Documents/UPWORK/PortFolio/LLM/PDF_chatbot/rag_env/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ndarray\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HfApi, HfFolder, Repository, hf_hub_url, cached_download\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn, Tensor, device\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'cached_download' from 'huggingface_hub' (/Users/subhratarakesh/Documents/UPWORK/PortFolio/LLM/PDF_chatbot/rag_env/lib/python3.10/site-packages/huggingface_hub/__init__.py)"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting huggingface_hub==0.16.4\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: filelock in ./rag_env/lib/python3.10/site-packages (from huggingface_hub==0.16.4) (3.18.0)\n",
      "Requirement already satisfied: fsspec in ./rag_env/lib/python3.10/site-packages (from huggingface_hub==0.16.4) (2025.5.1)\n",
      "Requirement already satisfied: requests in ./rag_env/lib/python3.10/site-packages (from huggingface_hub==0.16.4) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./rag_env/lib/python3.10/site-packages (from huggingface_hub==0.16.4) (4.67.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./rag_env/lib/python3.10/site-packages (from huggingface_hub==0.16.4) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./rag_env/lib/python3.10/site-packages (from huggingface_hub==0.16.4) (4.14.1)\n",
      "Requirement already satisfied: packaging>=20.9 in ./rag_env/lib/python3.10/site-packages (from huggingface_hub==0.16.4) (24.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./rag_env/lib/python3.10/site-packages (from requests->huggingface_hub==0.16.4) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./rag_env/lib/python3.10/site-packages (from requests->huggingface_hub==0.16.4) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./rag_env/lib/python3.10/site-packages (from requests->huggingface_hub==0.16.4) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./rag_env/lib/python3.10/site-packages (from requests->huggingface_hub==0.16.4) (2025.6.15)\n",
      "Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "Installing collected packages: huggingface_hub\n",
      "  Attempting uninstall: huggingface_hub\n",
      "    Found existing installation: huggingface-hub 0.33.2\n",
      "    Uninstalling huggingface-hub-0.33.2:\n",
      "      Successfully uninstalled huggingface-hub-0.33.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "transformers 4.53.1 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 0.16.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed huggingface_hub-0.16.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install huggingface_hub==0.16.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in ./rag_env/lib/python3.10/site-packages (25.1.1)\n",
      "Found existing installation: huggingface-hub 0.16.4\n",
      "Uninstalling huggingface-hub-0.16.4:\n",
      "  Successfully uninstalled huggingface-hub-0.16.4\n",
      "Found existing installation: sentence-transformers 2.2.2\n",
      "Uninstalling sentence-transformers-2.2.2:\n",
      "  Successfully uninstalled sentence-transformers-2.2.2\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-5.0.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting huggingface_hub==0.16.4\n",
      "  Using cached huggingface_hub-0.16.4-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: filelock in ./rag_env/lib/python3.10/site-packages (from huggingface_hub==0.16.4) (3.18.0)\n",
      "Requirement already satisfied: fsspec in ./rag_env/lib/python3.10/site-packages (from huggingface_hub==0.16.4) (2025.5.1)\n",
      "Requirement already satisfied: requests in ./rag_env/lib/python3.10/site-packages (from huggingface_hub==0.16.4) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./rag_env/lib/python3.10/site-packages (from huggingface_hub==0.16.4) (4.67.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./rag_env/lib/python3.10/site-packages (from huggingface_hub==0.16.4) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./rag_env/lib/python3.10/site-packages (from huggingface_hub==0.16.4) (4.14.1)\n",
      "Requirement already satisfied: packaging>=20.9 in ./rag_env/lib/python3.10/site-packages (from huggingface_hub==0.16.4) (24.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in ./rag_env/lib/python3.10/site-packages (from sentence-transformers) (4.53.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./rag_env/lib/python3.10/site-packages (from sentence-transformers) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in ./rag_env/lib/python3.10/site-packages (from sentence-transformers) (1.7.0)\n",
      "Requirement already satisfied: scipy in ./rag_env/lib/python3.10/site-packages (from sentence-transformers) (1.15.3)\n",
      "INFO: pip is looking at multiple versions of sentence-transformers to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading sentence_transformers-4.0.2-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading sentence_transformers-4.0.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading sentence_transformers-4.0.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading sentence_transformers-3.4.1-py3-none-any.whl.metadata (10 kB)\n",
      "  Downloading sentence_transformers-3.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "INFO: pip is still looking at multiple versions of sentence-transformers to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading sentence_transformers-3.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "  Downloading sentence_transformers-3.2.1-py3-none-any.whl.metadata (10 kB)\n",
      "  Downloading sentence_transformers-3.2.0-py3-none-any.whl.metadata (10 kB)\n",
      "  Downloading sentence_transformers-3.1.1-py3-none-any.whl.metadata (10 kB)\n",
      "  Downloading sentence_transformers-3.1.0-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting numpy<2.0.0 (from sentence-transformers)\n",
      "  Downloading numpy-1.26.4-cp310-cp310-macosx_10_9_x86_64.whl.metadata (61 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in ./rag_env/lib/python3.10/site-packages (from sentence-transformers) (2.2.6)\n",
      "Requirement already satisfied: Pillow in ./rag_env/lib/python3.10/site-packages (from sentence-transformers) (11.3.0)\n",
      "INFO: pip is looking at multiple versions of transformers to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting transformers<5.0.0,>=4.34.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.53.0-py3-none-any.whl.metadata (39 kB)\n",
      "  Downloading transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
      "  Downloading transformers-4.52.3-py3-none-any.whl.metadata (40 kB)\n",
      "  Downloading transformers-4.52.2-py3-none-any.whl.metadata (40 kB)\n",
      "  Downloading transformers-4.52.1-py3-none-any.whl.metadata (38 kB)\n",
      "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "  Downloading transformers-4.51.2-py3-none-any.whl.metadata (38 kB)\n",
      "INFO: pip is still looking at multiple versions of transformers to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading transformers-4.51.1-py3-none-any.whl.metadata (38 kB)\n",
      "  Downloading transformers-4.51.0-py3-none-any.whl.metadata (38 kB)\n",
      "  Downloading transformers-4.50.3-py3-none-any.whl.metadata (39 kB)\n",
      "  Downloading transformers-4.50.2-py3-none-any.whl.metadata (39 kB)\n",
      "  Downloading transformers-4.50.1-py3-none-any.whl.metadata (39 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading transformers-4.50.0-py3-none-any.whl.metadata (39 kB)\n",
      "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "  Downloading transformers-4.48.3-py3-none-any.whl.metadata (44 kB)\n",
      "  Downloading transformers-4.48.2-py3-none-any.whl.metadata (44 kB)\n",
      "  Downloading transformers-4.48.1-py3-none-any.whl.metadata (44 kB)\n",
      "  Downloading transformers-4.48.0-py3-none-any.whl.metadata (44 kB)\n",
      "  Downloading transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n",
      "  Downloading transformers-4.47.0-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
      "  Downloading transformers-4.46.2-py3-none-any.whl.metadata (44 kB)\n",
      "  Downloading transformers-4.46.1-py3-none-any.whl.metadata (44 kB)\n",
      "  Downloading transformers-4.45.2-py3-none-any.whl.metadata (44 kB)\n",
      "  Downloading transformers-4.45.1-py3-none-any.whl.metadata (44 kB)\n",
      "  Downloading transformers-4.45.0-py3-none-any.whl.metadata (44 kB)\n",
      "  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading transformers-4.44.1-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading transformers-4.44.0-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading transformers-4.43.4-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading transformers-4.43.3-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading transformers-4.43.2-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading transformers-4.43.1-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading transformers-4.43.0-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading transformers-4.42.4-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading transformers-4.42.3-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading transformers-4.42.2-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading transformers-4.42.1-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading transformers-4.42.0-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading transformers-4.41.2-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading transformers-4.41.1-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading transformers-4.41.0-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading transformers-4.40.2-py3-none-any.whl.metadata (137 kB)\n",
      "  Downloading transformers-4.40.1-py3-none-any.whl.metadata (137 kB)\n",
      "  Downloading transformers-4.40.0-py3-none-any.whl.metadata (137 kB)\n",
      "  Downloading transformers-4.39.3-py3-none-any.whl.metadata (134 kB)\n",
      "  Downloading transformers-4.39.2-py3-none-any.whl.metadata (134 kB)\n",
      "  Downloading transformers-4.39.1-py3-none-any.whl.metadata (134 kB)\n",
      "  Downloading transformers-4.39.0-py3-none-any.whl.metadata (134 kB)\n",
      "  Downloading transformers-4.38.2-py3-none-any.whl.metadata (130 kB)\n",
      "  Downloading transformers-4.38.1-py3-none-any.whl.metadata (131 kB)\n",
      "  Downloading transformers-4.38.0-py3-none-any.whl.metadata (131 kB)\n",
      "  Downloading transformers-4.37.2-py3-none-any.whl.metadata (129 kB)\n",
      "  Downloading transformers-4.37.1-py3-none-any.whl.metadata (129 kB)\n",
      "  Downloading transformers-4.37.0-py3-none-any.whl.metadata (129 kB)\n",
      "  Downloading transformers-4.36.2-py3-none-any.whl.metadata (126 kB)\n",
      "  Downloading transformers-4.36.1-py3-none-any.whl.metadata (126 kB)\n",
      "  Downloading transformers-4.36.0-py3-none-any.whl.metadata (126 kB)\n",
      "  Downloading transformers-4.35.2-py3-none-any.whl.metadata (123 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./rag_env/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.11.6)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers<5.0.0,>=4.34.0->sentence-transformers)\n",
      "  Downloading tokenizers-0.15.2-cp310-cp310-macosx_10_12_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./rag_env/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: sympy in ./rag_env/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./rag_env/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./rag_env/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./rag_env/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./rag_env/lib/python3.10/site-packages (from requests->huggingface_hub==0.16.4) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./rag_env/lib/python3.10/site-packages (from requests->huggingface_hub==0.16.4) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./rag_env/lib/python3.10/site-packages (from requests->huggingface_hub==0.16.4) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./rag_env/lib/python3.10/site-packages (from requests->huggingface_hub==0.16.4) (2025.6.15)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./rag_env/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./rag_env/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./rag_env/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Using cached huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
      "Downloading transformers-4.35.2-py3-none-any.whl (7.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.15.2-cp310-cp310-macosx_10_12_x86_64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: huggingface_hub, tokenizers, transformers, sentence-transformers\n",
      "\u001b[2K  Attempting uninstall: tokenizersâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0/4\u001b[0m [huggingface_hub]\n",
      "\u001b[2K    Found existing installation: tokenizers 0.21.2[32m0/4\u001b[0m [huggingface_hub]\n",
      "\u001b[2K    Uninstalling tokenizers-0.21.2:â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0/4\u001b[0m [huggingface_hub]\n",
      "\u001b[2K      Successfully uninstalled tokenizers-0.21.2â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1/4\u001b[0m [tokenizers]\n",
      "\u001b[2K  Attempting uninstall: transformersâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1/4\u001b[0m [tokenizers]\n",
      "\u001b[2K    Found existing installation: transformers 4.53.1â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1/4\u001b[0m [tokenizers]\n",
      "\u001b[2K    Uninstalling transformers-4.53.1:â•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2/4\u001b[0m [transformers]\n",
      "\u001b[2K      Successfully uninstalled transformers-4.53.1â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2/4\u001b[0m [transformers]\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4/4\u001b[0m [sentence-transformers]ence-transformers]\n",
      "\u001b[1A\u001b[2KSuccessfully installed huggingface_hub-0.16.4 sentence-transformers-3.0.1 tokenizers-0.15.2 transformers-4.35.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip uninstall huggingface_hub sentence-transformers -y\n",
    "!pip install sentence-transformers huggingface_hub==0.16.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: deactivate: command not found\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
